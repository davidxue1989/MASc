\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Visual Focus of Attention Estimation}{68}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Head Pose Estimation}{68}{section.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}3D Kinect Camera Approach}{68}{subsection.5.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{Approach Overview}{68}{section*.76}}
\newlabel{sec:approachOverview}{{5.1.1}{68}{Approach Overview}{section*.76}{}}
\citation{rusu20113d}
\citation{pirovano2011kinfu}
\citation{newcombe2011kinectfusion}
\citation{pirovano2011kinfu}
\citation{newcombe2011kinectfusion}
\citation{newcombe2011kinectfusion}
\citation{tomasi1998bilateral}
\citation{pirovano2011kinfu}
\citation{pirovano2011kinfu}
\@writefile{toc}{\contentsline {subsubsection}{KinFu Head Modeling}{69}{section*.77}}
\@writefile{toc}{\contentsline {paragraph}{How KinFu Works}{69}{section*.78}}
\@writefile{toc}{\contentsline {subparagraph}{Preprocessing}{69}{section*.79}}
\citation{pirovano2011kinfu}
\citation{pirovano2011kinfu}
\citation{pirovano2011kinfu}
\citation{low2004linear}
\citation{low2004linear}
\citation{low2004linear}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces A bilateral filter applied to a 2D color image. The left is the original, while the right is filtered, resulting in removal of noise, figure adapted from \cite  {pirovano2011kinfu}\relax }}{70}{figure.caption.80}}
\newlabel{fig:bilateralFiltering}{{5.1}{70}{A bilateral filter applied to a 2D color image. The left is the original, while the right is filtered, resulting in removal of noise, figure adapted from \cite {pirovano2011kinfu}\relax }{figure.caption.80}{}}
\@writefile{toc}{\contentsline {subparagraph}{Alignment}{70}{section*.82}}
\citation{newcombe2011kinectfusion}
\citation{pirovano2011kinfu}
\citation{pirovano2011kinfu}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces A 3-level multi-resolution pyramid, figure adapted from \cite  {pirovano2011kinfu}\relax }}{71}{figure.caption.81}}
\newlabel{fig:resolutionPyramid}{{5.2}{71}{A 3-level multi-resolution pyramid, figure adapted from \cite {pirovano2011kinfu}\relax }{figure.caption.81}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Point-to-plane error between two surfaces, figure adapted from \cite  {low2004linear}\relax }}{71}{figure.caption.83}}
\newlabel{fig:pointToPlaneError}{{5.3}{71}{Point-to-plane error between two surfaces, figure adapted from \cite {low2004linear}\relax }{figure.caption.83}{}}
\@writefile{toc}{\contentsline {subparagraph}{Surface Reconstruction}{72}{section*.84}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces A illustration of creating an 1D TSDF, figure adapted from \cite  {pirovano2011kinfu}\relax }}{72}{figure.caption.85}}
\newlabel{fig:TSDF}{{5.4}{72}{A illustration of creating an 1D TSDF, figure adapted from \cite {pirovano2011kinfu}\relax }{figure.caption.85}{}}
\citation{pirovano2011kinfu}
\@writefile{toc}{\contentsline {paragraph}{Using KinFu with Kinect2 Camera}{73}{section*.86}}
\@writefile{toc}{\contentsline {paragraph}{Using KinFu for Head Modeling}{73}{section*.87}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces The 3D Kinect Camera Approach Results: we start by grabbing a frame from the Kinect depth camera (a), then we fit the 3D head model to the depth frame (b), after which we project the head model mesh onto the color camera image plane (c), so as to associate the color pixels with the head model mesh (d), and lastly forming the 3D color point cloud (e).\relax }}{74}{figure.caption.88}}
\newlabel{fig:headTrackingResults}{{5.5}{74}{The 3D Kinect Camera Approach Results: we start by grabbing a frame from the Kinect depth camera (a), then we fit the 3D head model to the depth frame (b), after which we project the head model mesh onto the color camera image plane (c), so as to associate the color pixels with the head model mesh (d), and lastly forming the 3D color point cloud (e).\relax }{figure.caption.88}{}}
\@writefile{toc}{\contentsline {subsubsection}{KinFu Head Pose Tracking}{74}{section*.89}}
\@writefile{toc}{\contentsline {subsubsection}{Point Cloud Based Inverse Pose Transformation}{74}{section*.90}}
\@writefile{toc}{\contentsline {paragraph}{Colored Point Cloud}{74}{section*.91}}
\@writefile{toc}{\contentsline {subparagraph}{Head Model Mesh Projection}{75}{section*.92}}
\@writefile{toc}{\contentsline {subparagraph}{3D Coordinate Calculation}{75}{section*.93}}
\citation{bertalmio2000image}
\citation{mora2014eyediap}
\@writefile{toc}{\contentsline {paragraph}{Inverse Pose Transformation}{76}{section*.94}}
\@writefile{toc}{\contentsline {subsubsection}{Projection onto Camera Image Plane}{76}{section*.95}}
\@writefile{toc}{\contentsline {subsubsection}{Using the EYEDIAP Dataset}{76}{section*.97}}
\citation{herrera2012joint}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Inverse Pose Transformed Color Images of an Example Head: The top row displays images of the head for moderate range of poses, showing little distortion and blank spots; the bottom row displays failure cases, the first three shows extreme head poses resulting in some distortions and huge blank spots due to occlusion, the last image shows a failure case due to head tracking error, resulting in large distortions.\relax }}{77}{figure.caption.96}}
\newlabel{fig:inversePoseResults}{{5.6}{77}{Inverse Pose Transformed Color Images of an Example Head: The top row displays images of the head for moderate range of poses, showing little distortion and blank spots; the bottom row displays failure cases, the first three shows extreme head poses resulting in some distortions and huge blank spots due to occlusion, the last image shows a failure case due to head tracking error, resulting in large distortions.\relax }{figure.caption.96}{}}
\citation{funes2013person}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Eye Pose Estimation}{78}{subsection.5.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{Eye Image Cropping and Stabilization}{78}{section*.98}}
\@writefile{toc}{\contentsline {subsubsection}{Eye Image Descriptor}{78}{section*.99}}
\@writefile{toc}{\contentsline {subsubsection}{Adaptive Linear Regression (ALR)}{78}{section*.100}}
\@writefile{toc}{\contentsline {subsubsection}{Coupled Eyes Constraints}{78}{section*.101}}
\citation{funes2013person}
\citation{kim2001second}
\@writefile{toc}{\contentsline {subsubsection}{Solving ALR with Coupled Eyes Constraints}{79}{section*.102}}
\@writefile{toc}{\contentsline {subsubsection}{Training Examples Collection and Model Selection}{79}{section*.103}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Object Identification}{79}{section.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces The Gaussian ellipsoid formed by finding the point of minimal sum of squared distances from all gaze lines. Shown in red is the calculated point, shown in green are the closest point on each gaze line, shown in blue are the gaze lines. In the left figure, the person doing the object location calibration is standing on the right, looking to the left. The figure on the right shows the same plot rotated so the spread of the ellipsoid is seen more clearly.\relax }}{80}{figure.caption.104}}
\newlabel{fig:locCalibResults}{{5.7}{80}{The Gaussian ellipsoid formed by finding the point of minimal sum of squared distances from all gaze lines. Shown in red is the calculated point, shown in green are the closest point on each gaze line, shown in blue are the gaze lines. In the left figure, the person doing the object location calibration is standing on the right, looking to the left. The figure on the right shows the same plot rotated so the spread of the ellipsoid is seen more clearly.\relax }{figure.caption.104}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Discussion}{81}{section.5.3}}
\@setckpt{./tex/gaze_tracking_chp/gaze_tracking_chp}{
\setcounter{page}{82}
\setcounter{equation}{0}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{3}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{7}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{4}
\setcounter{Item}{41}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{76}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{LT@tables}{1}
\setcounter{LT@chunks}{1}
\setcounter{section@level}{1}
}
