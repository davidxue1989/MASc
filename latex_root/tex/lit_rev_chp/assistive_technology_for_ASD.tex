\section{Assistive Technology for ASD}
Assistive Technology (AT) refers to ``any device or piece of equipment that facilitates teaching new skills, augments existing skills, or otherwise reduces the impact of disability on daily functioning'' for individuals with disabilities \cite{lang2014assistive}.  Defined by Individuals with Disabilities Education Act Amendments of 1997, an AT is ``any item, piece of equipment, or product system ... that is used to increase, maintain, or improve functional capabilities of individuals with disabilities'' [Part A, Sec. 602 (1)].  The ATs used in the context of cognitive disabilities, such as those from dementias, stroke, mental illness, acquired brain injury and intellectual disability, are termed Assistive Technologies for Cognition (ATC) \cite{frank2004assistive}.  In this section, we will review the literatures of ATCs specifically for assisting individuals with ASD.

Two major reviews have been identified in this field: Lang et al.'s \cite{lang2014assistive} and Goldsmith et al.'s \cite{goldsmith2004use}.  In these reviews, roughly 60 studies were identified that targeted various abilities (or the lacking of abilities) of individuals with ASD using various forms of technologies as interventions.  The various targeted abilities can be divided into three groups: (a) communication skills, (b) social and emotional skills, and (c) daily living and other adaptive skills \cite{lang2014assistive}.  The various forms of technologies used in the interventions can be divided into auditory prompting, speech generating device, script training, tactile prompting, picture exchange communication systems, video modeling, and computer-based interventions.  In this section, we will focus on summarizing the results of the studies grouped by the targeted abilities, and critique the effectiveness and limitations of various forms of technologies used for each targeted ability group and draw parallel of the technologies used across targeted ability groups.

\subsection{Assistive Technology for Communication Skills}
Individuals with ASD experience varying degrees of disabilities in communication skills \cite{howlin2003outcome}.  Individuals with autism may experience limited speaking abilities or may fail to develop speech at all \cite{weitz1997aac}, while individuals with Asperger's syndrome often develop speech skills, but may fail to communicate well due to limited topics of interest, inabilities to recognize social cues, and anxieties related to social situations \cite{scheuermann2002teaching}.  In addition, individuals with ASD may develop speech stereotypies such as echolalia (i.e. repeating other's words verbatim) \cite{sigafoos2007assessing}.

Various ATCs have been developed to help individuals with ASD cope with or improve their communication skills.  Two major forms of technologies that help individuals with ASD cope are Picture Exchange Communication System (PECS) and Speech Generating Devices (SGD) a.k.a. Voice Output Communication Aid (VOCA).  Both PECS and SGD fall under the category of aided Augmentative and Alternative Communication (AAC) \cite{sigafoos2001conditional}, which relies on using visual cues such as symbols and pictures as a way for individuals with ASD to select the desired content of communication, since their visual processing abilities are thought to be often well developed (\cite{mirenda2001autism, shane2012applying}).

PECS is very simple technology wise, it involves the person with ASD to communicate by giving the other person a picture or symbol card representing their communicative intent \cite{bondy1994picture}.  There are four meta-analysis reviews investigating the effectiveness of using PECS as a communication system for people with ASD \cite{ganz2012meta, ganz2012metab, sulzer2009picture, tincani2010quantitative}.  PECS was identified as a promising intervention, and resulted in improved communication outcomes, and its effect size and that of the SGD's are among the greatest effect sizes compared against other AAC interventions.  PECS were also associated with increased speech produced for individuals already producing speech and increased social approaching in some individuals with ASD \cite{lang2014assistive}.  The mechanism of which PECS increases speech is not well understood \cite{preston2009review}, but hypotheses have been raised regarding how the caregiver's speech were encouraged during the PECS interactions with the user, and that served as a model for speech for the user \cite{yoder2006randomized}.

SGD is more advanced technology wise, it involves a portable device which can playback pre-recorded or synthesized speech messages when the person with ASD presses the panels or switches on the device.  Pictures or symbols are used to indicate what content is being played as speech.  Typical message includes requesting, commenting, and greeting, ``for example, a picture of a favorite toy may be used to indicate that the message 'May I have my toy please?' will be played if the corresponding panel on the SGD is activated'' \cite{lang2014assistive}.  There are four meta-analysis reviews investigating the effectiveness of using SGD as a communication system for people with ASD \cite{van2010communication, van2011assessing, ganz2012metab, ganz2013moderation}.  SGD was also identified as a viable intervention, it improved communication outcomes, and its effect size (and that of PECS') is greater than other AAC interventions (even had greater effect size than PECS for problem behavior treatment), and was the preferred device by some individuals with ASD over the PECS \cite{lang2014assistive}.  The increased speech was likely due to correct speech modeling during SGD's speech playback \cite{schlosser2008effects}.

Comparing between PECS and SGD, we see that both works as an effective alternative to individuals with ASD who are unable or unwilling to self-produce speech.  Interestingly, both devices are reported to increase self-produced speech from some individuals using them, and were believed to be the effects of correct speech modeling (directly from the device in SGD's case and from the caregiver in PECS' case).  In addition, the SGD holds advantage over PECS in that more complex messages can be delivered and communication attempts may be more easily understood by most communication partners \cite{mirenda2001autism}.  Also, SGD devices can take forms as an iPhone or iPod (the software can be loaded as an app), and the ubiquity of such handheld devices among typically developing peers may reduce the stigmatization of using SGD for communication \cite{kagohara2013using}.

Besides coping, there are also ATCs that teach and improve communication skills.  The only form of technology used for teaching communication skills currently found in literature is Computer Based Interventions (CBI).  CBI describes any software that runs on a computer aiming to improve certain skills for individuals with ASD through an interactive curriculum in a virtual learning environment \cite{lang2014assistive}.  The use of CBI for improving communication skils is reviewed by Ramdoss et al. \cite{ramdoss2011use}.  In the review, 10 studies with total of 70 participants (children 14 years or younger diagnosed with autism) were identified.  No studies with adults or individuals with Asperger's syndrome were included in the review.  The studies' aims can be divided into three groups: ones focusing on associating vocabulary words with pictures \cite{moore2000brief, hetzroni2005logos}; ones focusing on receptive identification and speech production of the vocabulary words \cite{heimann1995increasing, bernard1999enhancing, bosseler2003development, coleman2005using, massaro2006read}; and ones focusing on verbal initiation and relevance of speech during social settings \cite{parsons1993effect, simpson2004embedded, hetzroni2004effects}.  The softwares involved were either commercially available (e.g. Alpha program \cite{abledata2010alpha}, Baldi/Timo \cite{2005team}, HyperStudio \cite{mackiev2010welcome}, AbleData \cite{abledata2010alpha}, PowerPoint \cite{1997microsoft}, Speechviewer \cite{synapse2010the}) or were programmed by the research team.  All of the studies reported positive effects of using the CBI.  It's interesting to note that the softwares used share similarities in that they all implement some form of reinforcement schedules.  And for the latter two groups of studies, they all involved visually engaging graphics (e.g. a computer generated head in Baldi or animated color graphics of words in Alpha program), and relate the user to the vocabulary speech by synchronizing the graphics with the speech.


\subsection{Assistive Technology for Social Skills}
Lack of social skills is one of the diagnostic criteria for both autistic disorder and Asperger's syndrome \cite{spitzer1980diagnostic}.  Some symptoms include (a) lack of appropriate eye contact, (b) inability to develop peer relationships, (c) failure to initiate or maintain joint attention, and (d) lack of social and/or emotional reciprocity \cite{rao2008social}.

There are many ATCs focusing on either coping with and or improving social skills for individuals with ASD.  For the former, one of the ATCs identified by the review by Goldsmith et al. was Tactile Prompting devices \cite{goldsmith2004use}.  Tactile Prompting devices are portable devices individuals with ASD can carry and vibrate during the social interaction scenarios in attempt to promote self initiation to social interactions or promote responses to peer initiations.  The tactile prompting devices were either programmed to vibrate periodically or were controlled remotely by the researcher.  The studies identified in the review reported increased social interaction initiations for individuals with ASD including verbal initiations \cite{shabani2002increasing, taylor1998teaching} and handing communication cards \cite{taylor2004teaching}.

In addition to Tactile Prompting devices, another ATC has also been used for coping -- Script Training.  Script Training involves modeling a certain social interaction through a script and the individual with ASD is given a written copy of the script or hears it from a recording or a person reading it \cite{stevenson2000social}.  Not only does the script contain verbal speeches of interactions, the script may also contain prompts for the individual to follow, such as approach a potential conversation partner, initiate conversation, turn to the speaking person, maintain eye contact, wait until the person finishes talking, etc. \cite{wichnick2010effect}.  As an example, Wichnick et al. used a voice over recording device that plays back pre-recorded audio scripts when children with ASD and peers exchanged toys \cite{wichnick2010effect}.  Through continuous use, an improvement of response to peer initiation was observed, and the number of novel responses increased as scripts were faded.

Instead of coping with lack of social skills, there are ATCs that aim to teach and improve social skills.  By pooling the studies reviewed by Goldsmith et al. \cite{goldsmith2004use}, Lang et al. \cite{lang2014assistive}, Ramdoss et al. \cite{ramdoss2012computer}, and  Shukla-Mehta et al. \cite{shukla2009evaluating}, we've found two forms of ATCs that teach social skills to individuals with ASD: Computer Based Interventions and Video Modeling.

The CBI studies mainly focused on two groups of outcomes: The first group deals with promoting social responsiveness and interactive play, teaching social conflict resolution, and anger and anxiety management.  The second group deals with recognition of facial features, expressions, and interpreting emotions from faces, body language, and voices.  The results for using CBI for the first group were all positive, while the results for the second group were mixed but mainly positive \cite{ramdoss2012computer}.  Also, studies were unable to prove that CBI is better than face-to-face-training course in teaching social skills.  Lastly, there were very little evidence on the generalization of the social skills learned from CBI.  Possibly the reason why the second group had mixed results was because of the complexity of the skills involved is higher than those in group one, or the lack of such skills required in group two is more severe in individuals with ASD.  Instead of teaching, maybe in-vivo CBI solutions that aims for coping need to be developed to fill this gap.

Video Modeling is the other form of ATCs that teaches social skills.  As reviewed by Shukla-Mehta et al. \cite{shukla2009evaluating}, video modeling techniques can be divided into video modeling (VM), video self-modeling (VSM), and point-of-view video modeling (PVM).  VM involves the individual with ASD being asked to watch a video before instructed to practice certain target skill.  In the video, the target skill is modeled by an adult or a peer.  During watching of the video, the instructor prompts and provides reinforcers to the individual with ASD for attending relevant stimuli in the video.  It is expected that the individual would imitate the model's behaviors shown in the video when practicing the targeted skills immediately after \cite{bellini2007meta, graetz2006show}.  The individual would either watch a short video of some discrete target behaviors before practicing it in its entirety or watch a video clip of one step, practice the step, then watch the next clip and practice the next step.  It is found that for discrete target behaviors, a 3-5 min video is considered adequate for individuals with ASD \cite{buggey2005video}.  VSM is similar to VM except that the model in the video performing the targeted skills with the desired behaviors is the individual with ASD him/herself \cite{hitchcock2003video}.  This is based on the assumption that no one is a better model similar in age, gender, race, and other characteristics than oneself \cite{bandura1969principles, buggey1999training}.  VSM often involves showing videos of the individuals with ASD themselves successfully performing an exemplary behavior that is already in their repertoire or one they are learning.  This may mean carefully cutting out the scenes of undesired behaviors of the individual when making the videos, and could prove challenging for a novel skill the individual has not acquired yet.  PVM is similar to VM and VSM except that the video is shot from the visual perspective of the model as opposed to shot from a third person's perspective \cite{hine2006using}.  The purpose of PVM is that, when the individuals see the video, they see a smooth transition of what's expected of them from beginning to end of the routine.  Such techniques would ``promote visual comprehension and increase familiarity with materials and settings, and reduce task anxiety and inappropriate behaviors'' \cite{shukla2009evaluating}.

Shukla-Mehta et al.'s review included 26 studies, out of which the majority used VM, 4 studies used VSM, and only 2 studies used PVM \cite{shukla2009evaluating}.  The studies using VM focused on modeling verbal social initiations (e.g. compliments, social greetings, scripted and unscripted verbalization for pretend play etc.) as well as appropriate play behaviors (e.g. perspective taking, reciprocal play, sharing, eye contact, smiling, etc.).  The VSM and PVM studies also focused on similar goals as VM, with PVM also including a study that aimed to reduce severe problem behaviors (e.g. crying, screaming, dropping on the floor).  All of the studies reported positive outcomes, with some studies needing more than simply showing the videos to the individuals (instructional prompts, reinforcers and error correction were also implemented) to ensure acquisition, maintenance, and generalization of target skills.  It was also noted that the individual with ASD's skills in attending, imitation, visual processing and comprehension, matching-to-sample, and spatial ability influence the outcomes, thus planning the amount of content and length of video appropriate for the individual depends on these variables.  Lastly, there were no sufficient evidence suggesting the type of model (self, peer, familiar or unfamiliar adult) had an influence on VM's effectiveness.

\subsection{Assistive Technology for Daily Living and Other Adaptive Skills}
For an individual to function independently and successfully, daily living and other adaptively skills such as self-care (e.g. hand-washing), organization (e.g. time management), and community (e.g. grocery shopping) skills are crucial \cite{liss2001predictors}.  Individuals with ASD, however, often have a hard time acquiring such crucial skills and need to rely on the assistances of caregivers \cite{smith2012developmental}.

ATCs have been used to assist individuals with ASD in the skills outlined above.  There isn't a comprehensive literature review published on ATCs for daily living skills, however, Lang et al.'s review summarized nine studies in this field \cite{lang2014assistive}.  Almost all of the nine studies involved either a Computer Based Intervention (CBI) \cite{hutcherson2004computer}, a form of Video Modeling (VM \cite{rosenberg2010evaluating}, PVM \cite{bereznak2012video, shipley2002teaching, sigafoos2007evaluation, sigafoos2005computer, van2010comparison}), or a combination of the two called Computer Based Video Instructions (CBVI) \cite{ayres2009acquisition, mechling2010computer}.  The targeted tasks in the studies included preparing food, setting up table, grocery shopping, bus stop request, hand-washing, mailing letters, caring for pets, dish washing, and clothes folding.

CBI based ATCs and VM based ATCs both showed positive results in assisting individuals (diverse in age range) with ASD through the tasks.  CBI was particularly successful in creating a virtual environment in which individuals with ASD can focus on the controlled stimulus teaching them the task.  CBI is also good in giving consistent and immediate positive reinforcements automatically.  CBI focuses on teaching the skills needed to perform the target task in-vitro, and does not assist the performance in-vivo.  Thus, generalization of the skills learned from the virtual environment needs to be tested in the real life settings.  All CBI studies reviewed here involved some form of in-vivo generalization testing, and positive results were reported.

As effective as CBI, if not better, is video modeling (VM) interventions.  Of all the VM interventions, PVM was the most popular because it enables individuals with ASD with a first-person-view to better relate the materials presented in the video to the task at hand. However, positive results were reported for other VMs as well, giving evidence that video modeling in general is an effective way of teaching individuals with ASD the daily tasks required. There are no studies done using VSM, since the skills involved are novel and it is hard to produce videos of the individual performing an unlearned novel skill. From here on, we will not distinguish the different forms of VM. VM ATCs can be used as a in-vitro teaching tool, just like CBI, by letting the individual with ASD view the entirety of the video before performing the task. Studies involving in-vitro video modeling often needs verbal prompts and positive reinforcement in terms of verbal praises, toys or food rewards to motivate individual's concentration towards the training video. Although this method shows positive outcome, many of the studies reviewed here involved in-vivo video modeling.  This involves splitting the task into subtasks and display video for one subtask, then allow the individual to perform that subtask, after which it displays the video for the next subtask, and so on. This has the advantage of managing the complexity of each subtask needing to be performed as well as assisting the individual with ASD to plan which subtask to perform next.  Another common practice in VM ATCs was that verbal instructions were delivered as a voice over in the video.  The verbal instructions were short phrases that either describe the subtask being performed in the video or describe the stimulus in the video the individual should pay attention to.  Not only can the VM based ATCs be used in-vivo, individuals with ASD can be taught to use them by themselves, enabling their independence in real world scenarios.  IPods and laptops have both been used in studies that demonstrated the ability of individuals with ASD to self prompt, by playing and pausing the model videos or by pressing the next button, at each subtask.  Such self prompting skills were taught by having the teacher first model the operation of the ATC in person or through video modeling, using an exemplar task.  Then after the training sessions, the teacher starts the individuals with ASD on the actual task, and encourages them to seek assistance from the ATC when they encountered problems they don't know how to solve.

Marrying the advantages of CBI and VM, CBVI shares the ability to create virtual training environment and deliver accurate reinforcement schedule like CBI, and is able to effectively train individuals with ASD the skills involved in the task like VM.  Positive results were reported by two studies.  In one study by Ayres et al., a computer program taught individuals with ASD preparing meals.  In this study, a modified system of least prompts (SLP) arrangement was used, with the prompting hierarchy being, from least to most intrusive: 1. independent (no prompts), 2. verbal prompt (short phrase of what to do), 3. video prompt (video modeling the subtask), 4. partial physical prompt (the computer shows visually where to click in order to execute the subtask, but requires the user to click it), 5. full physical prompt (the computer clicks for the user) \cite{ayres2009acquisition}.  In this arrangement, the individual with ASD is given a chance to complete each subtask without prompts, if not successful, a prompt with increasing level of intrusion is given, until the subtask is done either by the individual or by the computer.  This prompt hierarchy was useful in implementing prompt fading for the goal of promoting maintenance and independence.  Note however that the prompt hierarchy is easily implemented in-vitro since the computer has full knowledge of how well along the task the user is doing in the virtual environment it created.  However, for in-vivo prompting hierarchy, either a human or an artificial intelligence is needed for understanding user states.

Of all the studies reviewed (CBI, VM, and CBVI), there are a couple of common themes in their methodologies.  First, all the studies that are systematic and complete in their method tested for the effectiveness of ATC in the following areas: acquisition of skill with ATC, maintenance of skill without ATC, maintenance of skill over time, and generalization of skill across settings.  Of course, not all the studies need to show effectiveness of the ATC in all four areas, since this may be difficult for some studies (e.g. pilot studies that do not aim to have follow ups 3 months after) and inappropriate for others (e.g. acquisition without prompts were not the aims for some ATCs).  Second, individuals often need positive reinforcement during in-vivo task execution.  There are always either some sort of encouragement from the instructor (e.g. verbal praise) or a real motivating reason for the individual to succeed in the task (e.g. eat the popcorns made).

\subsection{Discussion}
\label{Sec:AT4ASDDiscussion}
From reviewing the ATCs literatures for assisting individuals with ASD, we've found several forms of technologies that are proven to work.  They differ in complexity technology wise, however, they share similarities in that they either teach the target skill in-vitro or help to cope with the lack of skills in-vivo.  In addition, some common techniques found across the different forms of technologies are: the ATC engages individuals with ASD visually, gives them direct instructions, shows them the exact model behavior expected of them, provides them a consistent and simplified environment to practice the skills, and motivate them through positive reinforcement.  The different forms of prompting modalities include audio prompting, tactile prompting, and visual prompting.

We saw that, for modeling techniques such as script training and video modeling, instructions and reinforcements were needed during the modeling session as well as during the task execution session.  The instructions served as a way to help the individual with ASD to focus on certain stimuli necessary to learn the skill during modeling, and to help the individual to stay on task during task execution.  The reinforcements served as motivations for the individual to stay engaged and motivated during the trials.

CBI stood out as a technology that's very versatile and proved to be useful for training many skill areas.  In general, it is speculated that the success of CBI was due to the following reasons: First, a computer is consistent and predictable and is believed to be the preferred instructional delivery modality for individuals with ASD who prefer routines \cite{ramdoss2011use}.  This puts CBI advantageous to caregiver based interventions.  Second, a computer provides a virtual learning environment that reduces distractions and controls for autism-specific learning characteristics (e.g. stimulus overselectivity) \cite{lovaas1979stimulus}.  This puts CBI advantageous to some ATCs that aim for in-vivo learning.  Lastly, a computer can accurately implement complex reinforcement schedules and prompt fading, promoting learning and generalization \cite{ramdoss2011useb}.  This puts CBI advantageous over video modeling, since CBI can incorporate video modeling as part of the curriculum, while providing reinforcement and prompt fading.

CBI maybe successful in teaching skills to individual with ASD in-vitro, the ultimate goal is for the individual to perform the skill learned in-vivo.  Although some generalizations of skills learned from CBI were shown, another strategy is to use ATC in-vivo.  An important focus of research in this strategy is how to get the individual with ASD to be self-sufficient with the ATC in-vivo.  There were three ways: train the individual with ASD to self operate the ATC, remote control the ATC, and have an automated ATC.  The second method does not provide true functional independence, since a remote operator is still needed.  But this method can be viewed as an intermediate prototype before full automation of the ATC, and is useful in testing the automated ATC without realizing its automation.  Thus, we will mainly compare the first and third method here.  The first method involves teaching the individual with ASD to self operate the ATC.  This has been shown to be feasible for several forms of ATCs (tactile prompting, verbal prompting, and video prompting).  However, it requires certain fine motor skills from the individual for manipulating the ATC's controls, and requires certain level of executive functioning to learn to seek help from the ATC.  The alternative is to use a fully automated ATC.  One basic form of automated ATC was to periodically play a certain prompt during task execution.  This strategy is simple to implement, but is often not as effective as if the prompt was delivered contingent to the context.  However, in order to do this, a computer program is needed that understands and tracks the context the user is in, and delivers the appropriate prompt when user needs it.  Such automation is feasible for CBI ATCs, since the virtual environment is fully controlled by the computer program.  However, for in-vivo ATCs to realize this automation, some form of artificial intelligence (AI) is needed that understands the real-life environment.  Up to date, the only ATC that fills this gap is COACH \cite{bimbrahw2012investigating}, which uses computer vision and AI to understand the current hand-washing task the user is undergoing and delivers prompts when the user does not execute a task within a preset time period, and delivers positive reinforcement when the user executes a task correctly.

Relating to the issue of promoting functional independence of individual with ASD using in-vivo ATCs, a common strategy adopted is prompt fading, where the prompts used were slowly tuned down over time in its specificity.  This has the effect of decreasing the individual with ASD's reliance on the prompts, in hope that one day the individual could execute the tasks without the ATC.  This in-vivo prompt fading strategy were shown to be successful in promoting generalization of a learned skill, and should be implemented for all in-vivo ATCs.  COACH also adheres to this requirement as well, implementing a hierarchy of prompts (video modeling, picture prompts, verbal prompts), and decreases the prompt level over time as user's skills progress.

In conclusion, we see that various forms of ATCs have been proven useful for assisting individuals with ASD, and COACH fills an unique gap by delivering fully automated prompts and reinforcements in-vivo.  It has the advantage of in-vivo ATCs, easing in the learning of a new skill in-vivo and ensuring generalization.  It also retains the advantage of in-vitro ATCs (e.g. CBI), providing consistent and accurate reinforcement schedules.  Thus, the approach that COACH offers is founded in good grounds.  This thesis aims to further improve COACH by exploring novel interaction modalities that better engage individuals with ASD, all the while preserving its in-vivo and CBI advantages.